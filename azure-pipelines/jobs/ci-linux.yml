parameters:
  job: null
  pool:
    name: Hosted Ubuntu 1604
  imageName: null

jobs:
- job: ${{ parameters.job }}
  pool: ${{ parameters.pool }}
  timeoutInMinutes: 280
  variables:
    # Use ":z" to set selinux flag for sharing in build-owned root dir. https://docs.docker.com/storage/bind-mounts/#configure-the-selinux-label
    docker.agentSrc.map: -v $(Build.SourcesDirectory):/agentSrc:z
    docker.agentSrc.work: -w /agentSrc
    docker.run: docker run --rm
    docker.root.map: -v $(rootDirectory):/root:z
    docker.src.map: -v $(rootDirectory)/source-build-reference-packages/src:/src:z
    docker.src.work: -w /src
    docker.staging.map: -v $(stagingDirectory):/staging:z
    imageName: ${{ parameters.imageName }}
    rootDirectory: $(Build.SourcesDirectory)/..
    stagingDirectory: $(rootDirectory)/source-build-reference-packages/staging
    _PublishUsingPipelines: true

  steps:
  - template: ../steps/docker-cleanup-linux.yml

  # Create working directory and copy source into it.
  - script: |
      set -x
      df -h
      $(docker.run) $(docker.root.map) $(docker.agentSrc.map) $(docker.agentSrc.work) $(imageName) bash -c '
        mkdir -p /root/source-build-reference-packages/staging
        rm -rf /root/source-build-reference-packages/src
        mkdir -p /root/source-build-reference-packages/src
        cp -r . /root/source-build-reference-packages/src'
    displayName: Clean source-build-reference-packages directory and copy source from cloned directory

  # Build reference packages
  - script: |
      set -x
      df -h
      $(docker.run) $(docker.src.map) $(docker.src.work) $(imageName) ./build.sh
    displayName: Build reference packages
    timeoutInMinutes: 280

  # Create reference packages tarball
  - script: |
      set -x
      df -h
      $(docker.run) $(docker.src.map) $(docker.src.work) $(imageName) ./publish.sh $(BUILD.BUILDNUMBER) --ci
    displayName: Create reference packages tarball
    condition: "
        and(
            succeeded(),
            eq(variables['System.TeamProject'], 'public'),
            in(variables['Build.Reason'], 'PullRequest')
        )"
    continueOnError: true
  # Below step's sourced from : https://github.com/dotnet/runtime/blob/4e72737a8ec246297bce916ad747e4a2fb1265ac/eng/pipelines/installer/jobs/base-job.yml#L455-L468
  # Files may be owned by root because builds don't set user ID. Later build steps run 'find' in
  # the source tree, which fails due to permissions in the 'NetCore*-Int-Pool' queues. This step
  # prevents the failure by using chown to clean up our source tree.
  - script: |
      set -x
      docker run --rm \
        -v "$(Agent.BuildDirectory):/root/build" \
        -w /root/build \
        bash -c "chown -R $(id -u):$(id -g) *"
    displayName: Update file ownership from root to build agent account
    continueOnError: true
    condition: succeededOrFailed()

  # Create reference packages tarball and upload to azure storage
  - script: |
      set -x
      df -h
      pushd $(rootDirectory)/source-build-reference-packages/src
      ./publish.sh $(BUILD.BUILDNUMBER) --ci \
        /p:AzureAccountName=$(publish.blobStorage.account) \
        /p:AzureAccessToken=$(publish.blobStorage.accessToken) \
        /p:ContainerName=$(publish.blobStorage.container) \
        /p:DotNetPublishUsingPipelines=$(_PublishUsingPipelines) \
        /p:DotNetArtifactsCategory=$(_DotNetArtifactsCategory) \
        /p:ManifestName=source-build-reference-packages \
        /p:ManifestBuildId=$(BUILD.BUILDID) \
        /p:ManifestBranch=$(BUILD.SOURCEBRANCHNAME) \
        /p:ManifestCommit=$(BUILD.SOURCEVERSION)
    displayName: Create reference packages tarball and upload to azure storage
    condition: "
        and(
            succeeded(),
            ne(variables['System.TeamProject'], 'public'),
            notin(variables['Build.Reason'], 'PullRequest')
        )"
    continueOnError: true

  # Copy artifacts and logs to staging directory.
  - script: |
      set -x
      df -h
      $(docker.run) $(docker.staging.map) $(docker.src.map) $(docker.src.work) $(imageName) /bin/bash -c "
        mkdir /staging/logs

        find . -iname '*.binlog' \
          -exec cp {} --parents /staging/logs \;

        if [ -d ./artifacts/asset-manifests ]; then
            cp -r ./artifacts/asset-manifests /staging/
        fi
        if [ -d ./artifacts/tarball ]; then
            cp -r ./artifacts/tarball /staging/
        fi"
    displayName: Copy build logs and artifacts
    condition: always()
    continueOnError: true

  # Copy artifacts to staging - Copy to VSTS owned folder is done outside of docker so copied files
  # have correct ownership so VSTS can clean them up later.
  - task: CopyFiles@2
    condition: always()
    continueOnError: true
    inputs:
      sourceFolder: $(stagingDirectory)
      targetFolder: $(Build.ArtifactStagingDirectory)

  # Publish artifacts.
  - task: PublishBuildArtifacts@1
    displayName: Publish Artifacts
    condition: always()
    continueOnError: true
    inputs:
      PathtoPublish: $(Build.ArtifactStagingDirectory)
      ArtifactName: All_Artifacts
      ArtifactType: Container

  # Clean up working directory.
  - script: $(docker.run) $(docker.root.map) $(imageName) bash -c 'rm -rf /root/source-build-reference-packages'
    displayName: Clean working directory
    condition: always()
    continueOnError: true

  - template: ../steps/docker-cleanup-linux.yml
